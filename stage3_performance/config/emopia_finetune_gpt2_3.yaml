data_loader:
  batch_size: 4
  data_path: events/m2p/emopia_m2p_{}/events
  train_split: events/m2p/emopia_m2p_functional/data_splits/train.pkl
  val_split: events/m2p/emopia_m2p_functional/data_splits/valid.pkl
  vocab_path: events/m2p/emopia_m2p_{}/dictionary.pkl
model:
  d_embed: 256
  d_ff: 768
  d_model: 256
  feature_map:
    n_dims: 64
  max_len: 768
  n_head: 4
  n_layer: 6 
  use_segemb: true
  n_segment_types: 2
training:
  gpuid: 0
  ckpt_dir: ckpt/perf/emopia_finetune_gpt2
  ckpt_interval: 10
  log_interval: 50
  lr: 1.0e-05
  lr_scheduler:
    T_max: 500000
    eta_min: 1.0e-06
  num_epochs: 1000
  trained_optim: ckpt\perf\pop1k7_full_song_functional_gpt2\optim\ep190_loss0.604_optim.pt
  trained_params: ckpt\perf\pop1k7_full_song_functional_gpt2\params\ep190_loss0.604_params.pt
  inference_params: null
  warmup_steps: 200
  accum_steps: 2