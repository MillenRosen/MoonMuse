{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save dir: events/emo_dstg/emopia_lead2full_functional/events\n",
      "convert midi to events ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1071/1071 [00:29<00:00, 36.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whether transpose_to_C: False, whether relative_chord: True, whether relative_melody: True\n",
      "read and filter available clips ...\n",
      "# available clips: 18643\n",
      "convert clips to midi ...\n",
      "midi dir: midi_data/HookTheory\\midis_chord11_functional\n",
      "# midi files:  18542\n",
      "convert midi to lead sheet ...\n",
      "save dir: events/emo_dstg/hooktheory_leadsheet_functional/events\n",
      "load keyname for HookTheory clips ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26175/26175 [00:00<00:00, 464468.30it/s]\n",
      "100%|██████████| 18542/18542 [01:34<00:00, 196.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples: 18108\n",
      "events/emo_dstg/pop1k7_lead2full_functional/events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1747/1747 [01:09<00:00, 25.28it/s]\n"
     ]
    }
   ],
   "source": [
    "%run representations/midi2events_emopia.py -r functional -e lead2full\n",
    "%run representations/midi2events_hooktheory.py -r functional -e 4\n",
    "%run representations/midi2events_pop1k7.py -r functional -e lead2full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > splitting EMOPIA+ dataset\n",
      " > num files:  1071\n",
      " > train, valid: 983 88\n",
      "\n",
      " > splitting Hooktheory dataset\n",
      " > num files:  18108\n",
      " > train, valid: 16297 1811\n",
      "\n",
      " > splitting dataset events/emo_dstg/pop1k7_lead2full_functional/events\n",
      " > num files:  1747\n",
      " > train, valid: 1572 175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run representations/data_splits.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1071/1071 [00:08<00:00, 133.40it/s]\n",
      "100%|██████████| 18108/18108 [00:33<00:00, 542.94it/s]\n",
      "100%|██████████| 1747/1747 [00:19<00:00, 87.57it/s] \n",
      "100%|██████████| 1071/1071 [00:04<00:00, 227.86it/s]\n",
      "100%|██████████| 1747/1747 [00:27<00:00, 62.73it/s]\n",
      "100%|██████████| 1071/1071 [00:07<00:00, 146.45it/s]\n",
      "100%|██████████| 1747/1747 [01:22<00:00, 21.18it/s]\n",
      "100%|██████████| 1071/1071 [00:29<00:00, 36.03it/s] \n",
      "100%|██████████| 1747/1747 [01:04<00:00, 27.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from representations.pkl_event import modify_from_pkl_dir\n",
    "\n",
    "in_d = {'emopia': r'events\\emo_dstg\\emopia_lead2full_functional\\events',\n",
    "             'hooktheory': r'events\\emo_dstg\\hooktheory_leadsheet_functional\\events',\n",
    "             'pop1k7': r'events\\emo_dstg\\pop1k7_lead2full_functional\\events'}\n",
    "\n",
    "out_d = {'hooktheory_chord': r'events\\chord\\hooktheory_chord_functional\\events',\n",
    "              'emopia_chord': r'events\\chord\\emopia_chord_functional\\events',\n",
    "              'pop1k7_chord': r'events\\chord\\pop1k7_chord_functional\\events',\n",
    "              'emopia_c2m': r'events\\c2m\\emopia_c2m_functional\\events',\n",
    "              'pop1k7_c2m': r'events\\c2m\\pop1k7_c2m_functional\\events',\n",
    "              'emopia_m2p': r'events\\m2p\\emopia_m2p_functional\\events',\n",
    "              'pop1k7_m2p': r'events\\m2p\\pop1k7_m2p_functional\\events',\n",
    "              'emopia_fill': r'events\\fill\\emopia_fill_functional\\events',\n",
    "              'pop1k7_fill': r'events\\fill\\pop1k7_fill_functional\\events'}\n",
    "\n",
    "modify_from_pkl_dir(in_d['emopia'], out_d['emopia_chord'], track_name='Full', mode='chord', pos=2)\n",
    "modify_from_pkl_dir(in_d['hooktheory'], out_d['hooktheory_chord'], track_name='Full', mode='chord', pos=1)\n",
    "modify_from_pkl_dir(in_d['pop1k7'], out_d['pop1k7_chord'], track_name='Full', mode='chord', pos=2)\n",
    "\n",
    "modify_from_pkl_dir(in_d['emopia'], out_d['emopia_c2m'], track_name='Full', mode='c2m', pos=2)\n",
    "modify_from_pkl_dir(in_d['pop1k7'], out_d['pop1k7_c2m'], track_name='Full', mode='c2m', pos=2)\n",
    "\n",
    "modify_from_pkl_dir(in_d['emopia'], out_d['emopia_m2p'], track_name='Full', mode='m2p', pos=2)\n",
    "modify_from_pkl_dir(in_d['pop1k7'], out_d['pop1k7_m2p'], track_name='Full', mode='m2p', pos=2)\n",
    "\n",
    "modify_from_pkl_dir(in_d['emopia'], out_d['emopia_fill'], track_name='Full', mode='performance', pos=2)\n",
    "modify_from_pkl_dir(in_d['pop1k7'], out_d['pop1k7_fill'], track_name='Full', mode='performance', pos=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > root: events\\chord\\hooktheory_chord_functional\n",
      " > num files: 18108\n",
      " > num qualities: 12 num roots: 13\n",
      " > Pass Note\n",
      " > num classes: 60\n",
      "\n",
      " > root: events\\chord\\emopia_chord_functional\n",
      " > num files: 1071\n",
      " > num qualities: 12 num roots: 13\n",
      " > Pass Note\n",
      " > num classes: 60\n",
      "\n",
      " > root: events\\c2m\\emopia_c2m_functional\n",
      " > num files: 1071\n",
      " > num classes: 97\n",
      "\n",
      " > root: events\\c2m\\pop1k7_c2m_functional\n",
      " > num files: 1747\n",
      " > num classes: 97\n",
      "\n",
      " > root: events\\m2p\\emopia_m2p_functional\n",
      " > num files: 1071\n",
      " > num classes: 221\n",
      "\n",
      " > root: events\\m2p\\pop1k7_m2p_functional\n",
      " > num files: 1747\n",
      " > num classes: 221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run representations/build_dictionary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': 'cuda', 'pretrained_optim_path': None, 'pretrained_param_path': None, 'inference_param_path': None, 'model': {'d_word_embed': 256, 'pre_lnorm': True, 'decoder': {'n_layer': 6, 'n_head': 4, 'd_model': 256, 'd_ff': 512, 'dropout': 0.1, 'mem_len': 0, 'tgt_len': 256}}, 'data': {'data_dir': 'events\\\\chord\\\\hooktheory_chord_functional\\\\events', 'train_split': 'events\\\\chord\\\\hooktheory_chord_functional\\\\data_splits\\\\train.pkl', 'val_split': 'events\\\\chord\\\\hooktheory_chord_functional\\\\data_splits\\\\valid.pkl', 'vocab_path': 'events\\\\chord\\\\hooktheory_chord_functional\\\\dictionary.pkl', 'batch_size': 32, 'max_n_seg': 1}, 'training': {'trained_steps': 0, 'trained_epochs': 0, 'warmup_steps': 200, 'lr_decay_steps': 500000, 'max_lr': 0.001, 'min_lr': 0.0001, 'max_epoch': 200, 'val_interval': 1, 'log_interval': 50, 'patience': 10}, 'output': {'ckpt_dir': 'ckpt/chord/hooktheory_chord', 'ckpt_interval': 5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[preparing data]: 16297it [00:03, 4680.29it/s]\n",
      "[preparing data]: 1811it [00:00, 2342.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dset lens] 16297 1811\n",
      "[info] # params: 3581501\n",
      "[epoch 001] training ...\n"
     ]
    }
   ],
   "source": [
    "%run stage1_chord/train.py -c stage1_chord/config/hooktheory_pretrain.yaml -r functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': 'cuda', 'pretrained_optim_path': 'ckpt\\\\chord\\\\hooktheory_chord_functional\\\\optim\\\\ep085_loss0.222_optim.pt', 'pretrained_param_path': 'ckpt\\\\chord\\\\hooktheory_chord_functional\\\\params\\\\ep085_loss0.222_params.pt', 'inference_param_path': None, 'model': {'d_word_embed': 256, 'pre_lnorm': True, 'decoder': {'n_layer': 6, 'n_head': 4, 'd_model': 256, 'd_ff': 512, 'dropout': 0.1, 'mem_len': 0, 'tgt_len': 256}}, 'data': {'data_dir': 'events\\\\chord\\\\emopia_chord_functional\\\\events', 'train_split': 'events\\\\chord\\\\emopia_chord_functional\\\\data_splits\\\\train.pkl', 'val_split': 'events\\\\chord\\\\emopia_chord_functional\\\\data_splits\\\\valid.pkl', 'vocab_path': 'events\\\\chord\\\\emopia_chord_functional\\\\dictionary.pkl', 'batch_size': 32, 'max_n_seg': 1}, 'training': {'trained_steps': 0, 'trained_epochs': 0, 'warmup_steps': 2000, 'lr_decay_steps': 500000, 'max_lr': 0.0001, 'min_lr': 1e-06, 'max_epoch': 300, 'val_interval': 1, 'log_interval': 50, 'patience': 30}, 'output': {'ckpt_dir': 'ckpt/chord/emopia_finetune/', 'ckpt_interval': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[preparing data]: 983it [00:13, 72.94it/s]\n",
      "[preparing data]: 88it [00:01, 64.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dset lens] 983 88\n",
      "[info] # params: 3581501\n",
      "[epoch 001] training ...\n"
     ]
    }
   ],
   "source": [
    "%run stage1_chord/train.py -c stage1_chord/config/emopia_finetune.yaml -r functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representation: functional, key determine: rule\n",
      "[nucleus parameters] t = 1.1, p = 0.97\n",
      "[info] # params: 3581501\n",
      "samp_00_Positive\n",
      "[global tempo] 110\n",
      "[info] generated Key_B, #events = 1\n",
      "[info] generated 1 bars, #events = 2\n",
      "[info] generated 2 bars, #events = 15\n",
      "[info] generated 3 bars, #events = 28\n",
      "[info] generated 4 bars, #events = 41\n",
      "[info] generated 5 bars, #events = 54\n",
      "[info] generated 6 bars, #events = 67\n",
      "[info] generated 7 bars, #events = 80\n",
      "[info] generated 8 bars, #events = 93\n",
      "[info] generated 9 bars, #events = 106\n",
      "[info] generated 10 bars, #events = 119\n",
      "[info] max events reached\n",
      "-- generated events: 129\n",
      "-- time elapsed: 1.46 secs\n",
      "samp_00_Negative\n",
      "[global tempo] 110\n",
      "[info] generated Key_a, #events = 1\n",
      "[info] generated 1 bars, #events = 2\n",
      "[info] generated 2 bars, #events = 15\n",
      "[info] generated 3 bars, #events = 28\n",
      "[info] generated 4 bars, #events = 41\n",
      "[info] generated 5 bars, #events = 54\n",
      "[info] generated 6 bars, #events = 67\n",
      "[info] generated 7 bars, #events = 80\n",
      "[info] generated 8 bars, #events = 93\n",
      "[info] generated 9 bars, #events = 106\n",
      "[info] generated 10 bars, #events = 119\n",
      "[info] max events reached\n",
      "-- generated events: 129\n",
      "-- time elapsed: 1.23 secs\n",
      "[info] finished generating 1 pieces, avg. time: 1.35 +/- 0.11 secs.\n"
     ]
    }
   ],
   "source": [
    "%run stage1_chord/inference.py -c stage1_chord/config/emopia_finetune.yaml -r functional -m chord -i ckpt/chord/emopia_finetune/params/best_params.pt -o generation/stage1_chord -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] transformer_helpers imported\n",
      "{'data_loader': {'batch_size': 4, 'data_path': 'events\\\\c2m\\\\pop1k7_c2m_{}\\\\events', 'train_split': 'events\\\\c2m\\\\pop1k7_c2m_functional\\\\data_splits\\\\train.pkl', 'val_split': 'events\\\\c2m\\\\pop1k7_c2m_functional\\\\data_splits\\\\valid.pkl', 'vocab_path': 'events\\\\c2m\\\\pop1k7_c2m_functional\\\\dictionary.pkl'}, 'model': {'d_embed': 256, 'd_ff': 512, 'd_model': 256, 'feature_map': {'n_dims': 64}, 'max_len': 768, 'n_head': 4, 'n_layer': 6, 'use_segemb': True, 'n_segment_types': 2}, 'training': {'gpuid': 0, 'ckpt_dir': 'ckpt/melody/pop1k7_{}_new_gpt2', 'ckpt_interval': 10, 'log_interval': 50, 'lr': 0.001, 'lr_scheduler': {'T_max': 500000, 'eta_min': 1e-05}, 'num_epochs': 1000, 'trained_optim': None, 'trained_params': None, 'inference_params': None, 'warmup_steps': 200, 'accum_steps': 2}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[preparing data]: 1572it [00:01, 852.08it/s]\n",
      "[preparing data]: 175it [00:00, 848.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] # training pieces: 1572\n",
      "# params: 17189474\n",
      "[epoch 001] training ...\n",
      "[epoch 001] # batches = 393\n"
     ]
    }
   ],
   "source": [
    "%run stage2_melody/train.py -c stage2_melody/config/pop1k7_pretrain_new_gpt2.yaml -m gpt2 -r functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] transformer_helpers imported\n",
      "{'data_loader': {'batch_size': 4, 'data_path': 'events\\\\c2m\\\\emopia_c2m_{}\\\\events', 'train_split': 'events\\\\c2m\\\\emopia_c2m_functional\\\\data_splits\\\\train.pkl', 'val_split': 'events\\\\c2m\\\\emopia_c2m_functional\\\\data_splits\\\\valid.pkl', 'vocab_path': 'events\\\\c2m\\\\emopia_c2m_{}\\\\dictionary.pkl'}, 'model': {'d_embed': 256, 'd_ff': 512, 'd_model': 256, 'feature_map': {'n_dims': 64}, 'max_len': 768, 'n_head': 4, 'n_layer': 6, 'use_segemb': True, 'n_segment_types': 2}, 'training': {'gpuid': 0, 'ckpt_dir': 'ckpt/melody/emopia_functional_new_gpt2', 'ckpt_interval': 10, 'log_interval': 50, 'lr': 1e-05, 'lr_scheduler': {'T_max': 500000, 'eta_min': 1e-06}, 'num_epochs': 1000, 'trained_optim': 'ckpt\\\\melody\\\\pop1k7_functional_new_gpt2\\\\optim\\\\best_optim.pt', 'trained_params': 'ckpt\\\\melody\\\\pop1k7_functional_new_gpt2\\\\params\\\\best_params.pt', 'patience': 50, 'inference_params': None, 'warmup_steps': 200, 'accum_steps': 2}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[preparing data]: 983it [00:00, 2621.19it/s]\n",
      "[preparing data]: 88it [00:00, 2645.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] # training pieces: 983\n",
      "# params: 17189474\n",
      "[epoch 001] training ...\n",
      "[epoch 001] # batches = 246\n"
     ]
    }
   ],
   "source": [
    "%run stage2_melody/train.py -c stage2_melody/config/emopia_finetune_new_gpt2.yaml -m gpt2 -r functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_loader': {'batch_size': 4, 'data_path': 'events\\\\c2m\\\\emopia_c2m_{}\\\\events', 'train_split': 'events\\\\c2m\\\\emopia_c2m_functional\\\\data_splits\\\\train.pkl', 'val_split': 'events\\\\c2m\\\\emopia_c2m_functional\\\\data_splits\\\\valid.pkl', 'vocab_path': 'events\\\\c2m\\\\emopia_c2m_{}\\\\dictionary.pkl'}, 'model': {'d_embed': 256, 'd_ff': 512, 'd_model': 256, 'feature_map': {'n_dims': 64}, 'max_len': 768, 'n_head': 4, 'n_layer': 6, 'use_segemb': True, 'n_segment_types': 2}, 'training': {'gpuid': 0, 'ckpt_dir': 'ckpt/melody/emopia_functional_new_gpt2', 'ckpt_interval': 10, 'log_interval': 50, 'lr': 1e-05, 'lr_scheduler': {'T_max': 500000, 'eta_min': 1e-06}, 'num_epochs': 1000, 'trained_optim': 'ckpt\\\\melody\\\\pop1k7_functional_new_gpt2\\\\optim\\\\best_optim.pt', 'trained_params': 'ckpt\\\\melody\\\\pop1k7_functional_new_gpt2\\\\params\\\\best_params.pt', 'patience': 50, 'inference_params': None, 'warmup_steps': 200, 'accum_steps': 2}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[preparing data]: 88it [00:00, 972.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] temp = 1.0 | top_p = 0.97\n",
      "[info] model loaded\n",
      "[info] generation/stage2_melody\\samp_00_Negative_Q2_melody.txt exists, skipping ...\n",
      "[info] generation/stage2_melody\\samp_00_Negative_Q3_melody.txt exists, skipping ...\n",
      "[info] generation/stage2_melody\\samp_00_Positive_Q1_melody.txt exists, skipping ...\n",
      "[info] generation/stage2_melody\\samp_00_Positive_Q4_melody.txt exists, skipping ...\n"
     ]
    }
   ],
   "source": [
    "%run stage2_melody/inference.py -c stage2_melody/config/emopia_finetune_new_gpt2.yaml -r functional -m gpt2 -i ckpt/melody/emopia_functional_new_gpt2/params/best_params.pt -od generation/stage2_melody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_loader': {'batch_size': 2, 'data_path': 'events\\\\m2p\\\\pop1k7_m2p_{}\\\\events', 'train_split': 'events\\\\m2p\\\\pop1k7_m2p_functional\\\\data_splits\\\\train.pkl', 'val_split': 'events\\\\m2p\\\\pop1k7_m2p_functional\\\\data_splits\\\\valid.pkl', 'vocab_path': 'events\\\\m2p\\\\pop1k7_m2p_{}\\\\dictionary.pkl'}, 'model': {'d_embed': 256, 'd_ff': 1024, 'd_model': 256, 'feature_map': {'n_dims': 64}, 'max_len': 1536, 'n_head': 4, 'n_layer': 6, 'use_segemb': True, 'n_segment_types': 2}, 'training': {'gpuid': 0, 'ckpt_dir': 'ckpt/perf/pop1k7_{}_new_gpt2', 'ckpt_interval': 10, 'log_interval': 50, 'lr': 0.001, 'lr_scheduler': {'T_max': 500000, 'eta_min': 1e-05}, 'num_epochs': 1000, 'trained_optim': None, 'trained_params': None, 'inference_params': None, 'warmup_steps': 200, 'accum_steps': 2, 'patience': 50}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[preparing data]: 1572it [00:39, 39.47it/s]\n",
      "[preparing data]: 175it [00:05, 32.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] # training pieces: 1572\n",
      "# params: 18829022\n",
      "[epoch 001] training ...\n",
      "[epoch 001] # batches = 786\n"
     ]
    }
   ],
   "source": [
    "%run stage3_performance/train.py -c stage3_performance/config/pop1k7_pretrain_new_gpt2.yaml -m gpt2 -r functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_loader': {'batch_size': 4, 'data_path': 'events\\\\m2p\\\\emopia_m2p_{}\\\\events', 'train_split': 'events\\\\m2p\\\\emopia_m2p_functional\\\\data_splits\\\\train.pkl', 'val_split': 'events\\\\m2p\\\\emopia_m2p_functional\\\\data_splits\\\\valid.pkl', 'vocab_path': 'events\\\\m2p\\\\emopia_m2p_{}\\\\dictionary.pkl'}, 'model': {'d_embed': 256, 'd_ff': 1024, 'd_model': 256, 'feature_map': {'n_dims': 64}, 'max_len': 1536, 'n_head': 4, 'n_layer': 6, 'use_segemb': True, 'n_segment_types': 2}, 'training': {'gpuid': 0, 'ckpt_dir': 'ckpt/perf/emopia_functional_new_gpt2', 'ckpt_interval': 10, 'log_interval': 50, 'lr': 1e-05, 'lr_scheduler': {'T_max': 500000, 'eta_min': 1e-06}, 'num_epochs': 1000, 'trained_optim': 'ckpt\\\\perf\\\\pop1k7_functional_new_gpt2\\\\optim\\\\best_optim.pt', 'trained_params': 'ckpt\\\\perf\\\\pop1k7_functional_new_gpt2\\\\params\\\\best_params.pt', 'inference_params': None, 'warmup_steps': 200, 'accum_steps': 2, 'patience': 50}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[preparing data]: 983it [00:17, 55.56it/s]\n",
      "[preparing data]: 88it [00:01, 50.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] # training pieces: 983\n",
      "# params: 18829022\n",
      "[epoch 001] training ...\n",
      "[epoch 001] # batches = 246\n"
     ]
    }
   ],
   "source": [
    "%run stage3_performance/train.py -c stage3_performance/config/emopia_finetune_new_gpt2.yaml -m gpt2 -r functional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 30.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_loader': {'batch_size': 4, 'data_path': 'events/m2p/emopia_m2p_{}/events', 'train_split': 'events/m2p/emopia_m2p_functional/data_splits/train.pkl', 'val_split': 'events/m2p/emopia_m2p_functional/data_splits/valid.pkl', 'vocab_path': 'events/m2p/emopia_m2p_{}/dictionary.pkl'}, 'model': {'d_embed': 256, 'd_ff': 768, 'd_model': 256, 'feature_map': {'n_dims': 64}, 'max_len': 768, 'n_head': 4, 'n_layer': 6, 'use_segemb': True, 'n_segment_types': 2}, 'training': {'gpuid': 0, 'ckpt_dir': 'ckpt/perf/emopia_finetune_gpt2', 'ckpt_interval': 10, 'log_interval': 50, 'lr': 1e-05, 'lr_scheduler': {'T_max': 500000, 'eta_min': 1e-06}, 'num_epochs': 1000, 'trained_optim': 'ckpt\\\\perf\\\\pop1k7_full_song_functional_gpt2\\\\optim\\\\ep190_loss0.604_optim.pt', 'trained_params': 'ckpt\\\\perf\\\\pop1k7_full_song_functional_gpt2\\\\params\\\\ep190_loss0.604_params.pt', 'inference_params': None, 'warmup_steps': 200, 'accum_steps': 2}}\n",
      "[preparing data] now at #0\n",
      "[info] model init completed\n",
      "[info] temp = 1.0 | top_p = 0.97\n",
      "[info] model loaded\n",
      "[info] generation/stage3_performance\\samp_00_Negative_Q2_melody_Q2_melody.txt exists, skipping ...\n",
      "Q3\n",
      "Key_C\n",
      "[info] generated 1 bars, #events = 64\n"
     ]
    }
   ],
   "source": [
    "from representations.pkl_conn import *\n",
    "input_directory = r'generation\\stage2_melody' \n",
    "output_directory = r'generation\\stage2_melody_conn'  \n",
    "process_directory(input_directory, output_directory, mode='melody')\n",
    "%run stage3_performance/inference.py -c stage3_performance/config/emopia_finetune_gpt2_3.yaml -r functional -m gpt2 -i ckpt/perf/emopia/ep010_loss0.813_params.pt -od generation/stage3_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
